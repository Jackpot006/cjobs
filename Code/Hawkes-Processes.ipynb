{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "from collections import defaultdict, Counter\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import math\n",
    "from itertools import chain\n",
    "#import matplotlib.cm as cm\n",
    "import statsmodels.api as sm\n",
    "from os import listdir\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.externals.six.moves.urllib.request import urlopen\n",
    "import json\n",
    "import random\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "import time\n",
    "import scipy as sp\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.stats import entropy\n",
    "import matplotlib.cm as cm\n",
    "from numpy.random import choice\n",
    "import itertools\n",
    "from sklearn import cluster, covariance, manifold\n",
    "import operator\n",
    "import itertools\n",
    "from datetime import datetime as dt\n",
    "import matplotlib.mlab as mlab\n",
    "from scipy.stats import norm\n",
    "import re\n",
    "from scipy import stats\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats.mstats import zscore\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Import Hawkes python module and the content will be in a subfolder labeled hawkes:\n",
    "https://github.com/stmorse/hawkes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('hawkes/')\n",
    "from MHP import MHP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Time series\n",
    "Hawkes only looks at the events at the same time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#1. Load DSDE jobs, and select skills that are in WoS\n",
    "J={}\n",
    "with open('time_series1.txt','r', encoding ='latin') as f:\n",
    "    for line in f:\n",
    "        skill=line.split('[')[0].strip().lower() # extract skill\n",
    "        vs=line.split('[')[1].split(']')[0].split(',') # vector : extract years + frequency - all content split by commas\n",
    "        dic=dict((int(i.split(':')[0]),int(i.split(':')[1])) for i in vs) # split year and freq\n",
    "        # KEY is skill, VALUE is year, freq \n",
    "        J[skill]=dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation \n",
    "Run this block to replace zero frequencies by 0.00001 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#JOBS\n",
    "JW={}\n",
    "for i in J:\n",
    "    JW[i] = J[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Add non-zero values\n",
    "for key, value in JW.items():\n",
    "\n",
    "    for i in JW[key]:\n",
    "        if JW[key][i]==0:\n",
    "            JW[key][i]=0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3.  split J by year and find total per year\n",
    "## JOB DATA TRANSFORMATION USE JW\n",
    "JT=defaultdict(int) # initializing first dictionary for collection/list\n",
    "for i in JW:\n",
    "    for year in JW[i]:\n",
    "        JT[year]+=JW[i][year]\n",
    "\n",
    "JN={}\n",
    "for i in JW:\n",
    "    dic=dict((k,v/float(JT[k])) for k,v in JW[i].items() if 2010<=k<=2016 and v!=0)#if 2010<=k<=2016 and v!=0 ) \n",
    "\n",
    "    if len(dic)==7:\n",
    "        JN[i]=dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# total frequencies per skills for influence graph\n",
    "JS=defaultdict(int)\n",
    "for i in J:\n",
    "    for year in J[i]:\n",
    "       # JS[i]+=float(str(round(J[i][year],0)))\n",
    "        JS[i]+=int(J[i][year])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOP Frequency Skills\n",
    "We select to 50 skills (words) by frequency that will be used in Hawkes process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#select top DSDE skills (top 50 still Bursing skills )\n",
    "N=50\n",
    "\n",
    "topSkills=sorted(list(zip(*sorted([(k,v) for k,v in J.items()],key=lambda x:-sum(x[1].values()))))[0][:N])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DSDE=dict((k,v) for k,v in JN.items() if k in topSkills)\n",
    "DSDE1={}\n",
    "for s in DSDE:\n",
    "    dic=DSDE[s]\n",
    "    t=sum(dic.values())\n",
    "    DSDE1[s]=dict((k,v/t) for k,v in dic.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hawkes Process\n",
    "\n",
    "Read - Steven Morse blog and thesis - https://stmorse.github.io/journal/Hawkes-python.html \n",
    "\n",
    "From personal communication with Steven:\n",
    "\n",
    "\"The MHP.generate_seq() method returns an array with shape (N, 2), each row an event, col 0 is time, col 1 is the label of the sequence where it occurred.  If you have already run generate_seq(), you should be able to then call EM() and get estimated parameters, EM() uses the same format and the data is saved as a variable of that class instance.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# simulate data for Hawkes Process estimation \n",
    "n=10# expanding \n",
    "Seq=[]\n",
    "skills=DSDE1.keys()\n",
    "nSkills=len(skills)\n",
    "for year in range(2010,2017):\n",
    "   # print(year)\n",
    "    for i in range(n):\n",
    "       # print(i)\n",
    "        ps=[DSDE1[s][year] for s in skills]\n",
    "       # print(len(ps))\n",
    "       # print(ps)\n",
    "        rp=np.random.uniform(0,1,len(ps))\n",
    "       # print(rp)\n",
    "        seq=(rp<ps).astype(int)\n",
    "       # print(seq)\n",
    "        Seq.append(seq)\n",
    "Seq=np.array(Seq)\n",
    "for i in range(Seq.shape[1]):\n",
    "    v=Seq[:,i]\n",
    "    v[v==1]=i+1\n",
    "td=[]\n",
    "t=0\n",
    "#print(len(Seq))\n",
    "\n",
    "for i in Seq:\n",
    "   #print(i)\n",
    "    for j in i:\n",
    "        t+=random.random()\n",
    "        if j!=0:\n",
    "            td.append([t,j])\n",
    "          # print(t,j)\n",
    "       # else:\n",
    "           # print(j)\n",
    "td=np.array(td)\n",
    "td[:,1]-=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TEST\n",
    "\n",
    "# simulate data for Hawke Process estimation \n",
    "n=10# expanding \n",
    "Seq=[]\n",
    "skills=DSDETest.keys()\n",
    "nSkills=len(skills)\n",
    "for year in range(2010,2017):\n",
    "   # print(year)\n",
    "    for i in range(n):\n",
    "       # print(i)\n",
    "        ps=[DSDETest[s][year] for s in skills]\n",
    "       # print(len(ps))\n",
    "       # print(ps)\n",
    "        rp=np.random.uniform(0,1,len(ps))\n",
    "       # print(rp)\n",
    "        seq=(rp<ps).astype(int)\n",
    "       # print(seq)\n",
    "        Seq.append(seq)\n",
    "Seq=np.array(Seq)\n",
    "for i in range(Seq.shape[1]):\n",
    "    v=Seq[:,i]\n",
    "    v[v==1]=i+1\n",
    "td=[]\n",
    "t=0\n",
    "#print(len(Seq))\n",
    "\n",
    "for i in Seq:\n",
    "   #print(i)\n",
    "    for j in i:\n",
    "        t+=random.random()\n",
    "        if j!=0:\n",
    "            td.append([t,j])\n",
    "          # print(t,j)\n",
    "       # else:\n",
    "           # print(j)\n",
    "td=np.array(td)\n",
    "td[:,1]-=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max eigenvalue: 24.66915\n",
      "(WARNING) Unstable.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "455"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialization models \n",
    "\n",
    "mhat = np.random.uniform(0,1, size=nSkills)\n",
    "ahat = np.random.uniform(0,1, size=(nSkills,nSkills))\n",
    "w = 3\n",
    "P = MHP(mu=mhat, alpha=ahat, omega=w)\n",
    "#P.generate_seq(60)\n",
    "P.data=td\n",
    "#P.plot_events()\n",
    "len(P.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After ITER 0 (old: -10000.000 new: -1.110)\n",
      " terms -454.9621, 404.8030, 50.1970\n",
      "After ITER 10 (old: -1.110 new: -4.894)\n",
      " terms -2100.3062, 328.6592, 126.3408\n",
      "Reached stopping criterion. (Old: -4.894 New: -4.895)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.773644208908081"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start=time.time()\n",
    "M=P.EM(ahat, mhat, w)[0]\n",
    "duration=time.time()-start\n",
    "duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Graph \n",
    "mM=np.mean(M)\n",
    "G=nx.from_numpy_matrix(M>mM) # Return a graph from numpy matrix.\n",
    "mapping=dict(zip(range(nSkills),skills))\n",
    "H=nx.relabel_nodes(G,mapping)\n",
    "pos=nx.spring_layout(H)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
